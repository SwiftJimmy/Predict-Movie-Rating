{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Anton Schaarschmidt     Matrikelnummer: 553613\n",
    "    Clemens Brauer          Matrikelnummer: 557110\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<b><h1><center>Hausarbeit Data Mining</center></h1></b>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Das Ziel unserer Hausarbeit ist, anhand von Schauspielern, Produktionsfirmen, Regisseuren, Drehbuchautoren und dem Hauptgenre die Beliebtheit von zukünftigen Filmen vorherzusagen indem diese in die Kategorien 'Schlechter Film', 'Durchschnittlicher Film' und 'Guter Film' klassifiziert werden. Als Maß der Beliebtheit stehen uns dafür die 3 Belibtheitsmetriken der IMDB, Rotten Tomato und Metacritic Webseite zur Verfügung. In den folgenden Kapiteln beschreiben wir dafür unsere Herangehensweise. \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Inhaltsverzeichnis\n",
    "1. [Daten](#Thema/Quelle)<br>\n",
    "    1.1 [Datenquellen](#1.1Quelle)<br>\n",
    "    1.2 [Struktur](#1.2Struktur)<br>\n",
    "    <br>\n",
    "2. [Datenaufbereitung](#Aufbereitung)<br>\n",
    "    2.1 [Datenimport](#2.1Datenimport)<br>\n",
    "    2.2 [Dimensionen entfernen](#2.2dimensionReduction)<br>\n",
    "    2.3 [Entfernung von Zeichen](#2.3CharacterRemoval)<br>\n",
    "    2.4 [Umrechnung von Währungen](#2.4HandleExchangeRates)<br>\n",
    "    2.5 [Umwandlung von Strings zu Listen](#2.5DirectorExtraktion)<br>\n",
    "    2.6 [Integer Dimensionen bestimmen](#2.6DimensionType)<br>\n",
    "    2.7 [Normierung der Bewertungsmetriken](#2.7RatingExtraktion)<br>\n",
    "    2.8 [Kalkulation von neuen Dimensionen](#2.8CalculationOfDimensions)<br>\n",
    "    2.9 [Fehlende Rotten Tomato Bewertungen mit Regression bestimmen](#2.9RegressionTomato)<br>\n",
    "    <br>\n",
    "3. [Datenanalyse](#3.Datenanalyse)<br>\n",
    "    3.1 [Verteilung der Filme pro Erscheinungsjahr](#3.1MovieReleaseYear)<br>\n",
    "    3.2 [Verteilung der Filme anhand ihrer Spieldauer](#3.2MovieRuntime)<br>\n",
    "    3.3 [Verteilung der Hauptgenre](#3.3GenreMovie)<br>\n",
    "    3.4 [Entwicklung der Einnahmen  und Ausgaben](#3.4BudgetGross)<br>\n",
    "    3.5 [Verteilung der Schauspieleranzahl](#3.5Actor)<br>\n",
    "    3.6 [Interaktives Diagramm](#3.6interactiveDiagram)<br>\n",
    "    3.7 [Bewertung der  Akteure](#3.7meanRatingMainGenre)<br>\n",
    "\n",
    "    <br> \n",
    "4. [Klassifizierung der Filmbeliebtheit](#4predictionMovie)<br> \n",
    "    4.1 [Bestimmung der Klassen](#4.1createClasses)<br> \n",
    "    4.2 [One Hot Encoding](#4.2classefier)<br> \n",
    "    4.3 [Klassifizierung und Ergebnisse](#4.3classefier)<br> \n",
    "    4.4 [Reduktion der Dimensionen](#4.4dimensionReduction)  <br> \n",
    "    4.5 [Ein Versuch mit Regression](#4.5tryRegression)   <br> \n",
    "    4.6 [Ergebnis](#4.6result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Daten <a name=\"Thema/Quelle\"></a>\n",
    "Für diese Abgabe haben wir uns einen Datensatz aus verschiedenen Informationen zu US Filmen aus den Jahren 1980 - 2019 durch Web Scraping und API Services zusammengestellt. In diesem Kapitel beschreiben wir \n",
    "\n",
    "   [1. die Quellen](#1.1Quelle)<br>\n",
    "   [2. die Struktur](#1.2Struktur)<br>\n",
    "\n",
    "unserer Daten.\n",
    "\n",
    "### 1.1 Datenquellen <a name=\"1.1Quelle\"></a>\n",
    "Leider konnten wir keine Quelle finden, welche uns kostenfrei eine große Menge an Informationen pro Film liefern konnte. Aus diesem Grund haben wir die Daten zu einzelnen Filmen aus verschiednenen Quellen bezogen. Um zu verhindern, dass wir viele Filme mit einem mehr oder weniger stark ausgeprägten Informationsgehalt erhalten, haben es einzelne Filme erst dann in unseren Datensatz geschafft, wenn wir über diese aus allen Quellen Informationen gewinnen konnten. Die folgenden Quellen wurden genutzt:\n",
    "\n",
    "- [OMDB Api](http://www.omdbapi.com)\n",
    "- [IMDB](https://www.imdb.com)\n",
    "- [Boxoffice Mojo](https://www.boxofficemojo.com/)\n",
    "- [The-Numbers](https://www.the-numbers.com/movie/budgets/all)\n",
    "\n",
    "### 1.2 Struktur <a name=\"1.2Struktur\"></a>\n",
    "\n",
    "Die Daten haben wir in einer JSON Datei gesichert. Diese beinhaltet die folgenden 48 Dimensionen für insgesammt 4507 Filme. \n",
    "\n",
    "| Attribut | Beschreibung | \n",
    "| :- | :--- | \n",
    "| Actors | Eine Liste aller Schauspieler in einer Rangordnung von Hauptdarsteller bis Nebendarsteller. | \n",
    "| BoxOffice | Einnahmen aus Kinovorstellungen. | \n",
    "| Country | Produktionsland. | \n",
    "| DVD | Datum an dem die DVD released wurde. | \n",
    "| Director | Film Regisseur/e. | \n",
    "| Domestic Gross | Gesamteinnahmen im Produktionsland. | \n",
    "| Genre | Durch Kommata getrennte Rangordnung der Genres eines Filmes von Haupt- bis Nebengenre. | \n",
    "| Language | Gesprochene Sprachen im Film. | \n",
    "| Metascore | Der Metascore ist Bewertungsmetric von der Website Metacritic.com. Scores werden von Filmkritikern vergeben, basierend auf deren Ruhm gewichtet und als Metascore zusammengefasst. | \n",
    "| Movie Name                    | Name des Filmes. |\n",
    "| NominationBAFTA               | Anzahl der Home of the British Academy of Film and Television Arts Award Nominierung/en. |\n",
    "| NominationEmmy                | Anzahl der Emmy Award Nominierung/en. |\n",
    "| NominationGoldenGlobe         | Anzahl der Golden Globe Nominierung/en.  |\n",
    "| NominationGrammy              | Anzahl der Grammy Nominierung/en. |\n",
    "| NominationOscar               | Anzahl der Oscar Nominierung/en. |\n",
    "| NominationTeenChoiceAward     | Anzahl der Teen Choice Award Nominierung/en. |\n",
    "| NominationVESAward            | Anzahl der VES Award Nominierung/en. |\n",
    "| NominationYoungArtistAwards   | Anzahl der Young Artist Award Nominierung/en.   |\n",
    "| NominationAnother             | Anzahl von weiteren Nominierung/en. |\n",
    "| Plot                          | Eine kurze Beschreibung der Filmhandlung. |\n",
    "| Poster                        | URL zum Filmposter. |\n",
    "| Production                    | Film-Produktionsfirma. |\n",
    "| Production Budget             | Das Budget für Filme. |\n",
    "| Rated                         | Kategorie der Altersfreigabe.  |\n",
    "| Ratings                       | Eine Lister der IMDB, Rotten Tomatos und Metacritic Bewertungen. |\n",
    "| Release Date                  | Datum der Veröffentlichung. |\n",
    "| Released                      | Datum der Veröffentlichung. |\n",
    "| Response                      | Antwort eines Api Aufrufes. |\n",
    "| Runtime                       | Spielzeit in Minuten. |\n",
    "| Title                         | Name des Filmes. |\n",
    "| TomatoRating                  | Rotten Tomato Bewertungung.  |\n",
    "| Type                          | Art des Filmes. In unserem Datensatz ist dies immer 'movie'. |\n",
    "| Website                       | URL zu der Film-Webseite. |\n",
    "| WinBAFTA                      | Anzahl der gewonnenen Home of the British Academy of Film and Television Arts Awards. |\n",
    "| WinEmmy                       | Anzahl der gewonnenen Emmy Awards.  |\n",
    "| WinGoldenGlobe                | Anzahl der gewonnenen Golden Globe Awards. |\n",
    "| WinGrammy                     | Anzahl der gewonnenen Grammy Awards. |\n",
    "| WinOscar                      | Anzahl der gewonnenen Oscar Awards. |\n",
    "| WinTeenChoiceAward            | Anzahl der gewonnenen Teen Choice Award Awards. |\n",
    "| WinVESAward                   | Anzahl der gewonnenen VES Award Awards. |\n",
    "| WinYoungArtistAwards          | Anzahl der gewonnenen Young Artist Award Awards. |\n",
    "| WinAnother                    | Anzahl der gewonnenen weiteren Awards. |\n",
    "| Worldwide Gross               | Weltweite Gesamteinnahmen. | \n",
    "| Writer                        | Durch Kommata getrennte Rangordnung der Autoren eines Filmes von Haupt- bis Co-Autoren.|\n",
    "| Year                          | Jahr der Filmveröffentlichung. |\n",
    "| imdbID                        | IMDB Identifikations-Nummer. |\n",
    "| imdbRating                    | IMDB Bewertungung. |\n",
    "| imdbVotes                     | Anzahl der IMDB Bewertungs-Abstimmungen. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Datenaufbereitung <a name=\"Aufbereitung\"></a>\n",
    "In diesem Kapitel beschreiben wir die Aufbereitung der Daten. Dafür gehen wir wie folgt vor: <br><br>\n",
    "        1 [Datenimport](#2.1Datenimport)<br>\n",
    "        2 [Dimensionen entfernen](#2.2dimensionReduction)<br>\n",
    "        3 [Entfernung von Zeichen](#2.3CharacterRemoval)<br>\n",
    "        4 [Umrechnung von Währungen](#2.4HandleExchangeRates)<br>\n",
    "        5 [Umwandlung von Strings zu Listen](#2.5DirectorExtraktion)<br>\n",
    "        6 [Integer Dimensionen bestimmen](#2.6DimensionType)<br>\n",
    "        7 [Normierung der Bewertungsmetriken](#2.7RatingExtraktion)<br>\n",
    "        8 [Kalkulation von neuen Dimensionen](#2.8CalculationOfDimensions)<br>\n",
    "        9 [Fehlende Rotten Tomato Bewertungen mit Regression bestimmen](#2.9RegressionTomato)<br>\n",
    "\n",
    "\n",
    "### 2.1 Datenimport <a name=\"2.1Datenimport\"></a>\n",
    "Wir importieren die Daten aus der MovieData.json Datei in ein Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2WA\n",
    "\n",
    "\n",
    "path = r\"\"\"JSONData/MovieData.json\"\"\"\n",
    "df = pd.read_json (path).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Dimensionen entfernen  <a name=\"2.2dimensionReduction\"></a>\n",
    "Einige der in Absatz [1.2 Struktur](#1.2Struktur) beschriebenen 48 Dimensionen sind für unsere Arbeit nicht von Relevanz und können gelöscht werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['BoxOffice', 'Country', 'DVD', 'Language', 'Movie Name', 'Plot', \n",
    "                         'Poster', 'Rated', 'Ratings', 'Release Date', 'Released', 'Response', 'Type', 'Website'])\n",
    "print('Anzahl der verbleibenden Dimensionen: ' + str(len(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Entfernung von Zeichen <a name=\"2.3CharacterRemoval\"></a>\n",
    "Die Daten 'Anzahl an IMDB Bewertungen', 'Rotten Tomato Bewertung' sowie die 'Laufzeit' beinhalten Zeichen, welche entfernt werden müssen.\n",
    "Beispiel:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['tt1634121'][['Runtime', 'imdbVotes', 'TomatoRating'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dafür werden einfach alle nicht numerischen Chars durch eine Regex Anweisung aus den Strings entfernt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Runtime'] = df['Runtime'].str.extract('(\\d+)', expand=False)\n",
    "df['TomatoRating'] = df['TomatoRating'].str.extract('(\\d+)', expand=False)\n",
    "df['Writer']= df['Writer'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "df['imdbVotes'] = df['imdbVotes'].str.replace(\",\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Ergebnis bleiben nur die Zahlenwerte erhalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['tt1634121'][['Runtime', 'imdbVotes', 'TomatoRating'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Umrechnung von Währungen <a name=\"2.4HandleExchangeRates\"></a>\n",
    "In dem Datensatz weisen Filme teilweise verschiedene Währungen für 'Domestic Gross', 'Worldwide Gross' und 'Production Budget' auf. Dies trifft beispielsweise für den Film <b>\"Intruders\"</b> zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['tt1634121'][['Domestic Gross','Worldwide Gross','Production Budget']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um einen Überblick über alle vorkommenden Währungen zu erhalten, durchsuchen wir 'Domestic Gross', 'Worldwide Gross' und 'Production Budget' nach ihren vorkommenden Währungszeichen und lassen uns diese anzeigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency =   list(map(lambda x: ''.join([i for i in x if not i.isdigit()]) ,df['Domestic Gross']))\n",
    "currency +=  list(map(lambda x: ''.join([i for i in x if not i.isdigit()]) ,df['Worldwide Gross']))\n",
    "currency +=  list(map(lambda x: ''.join([i for i in x if not i.isdigit()]) ,df['Production Budget']))\n",
    "dict((i, currency.count(i)) for i in currency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da '$' als die häufigste Währung auftritt, sollen alle anderen Währungen in US-Dollar umgerechnet werden. Dies haben wir mit Hilfe einer Exchange API realisiert, welche die benötigten Umrechnungskurse über einen Get Request liefert. Leider ist nicht erkennbar, welchen Stand die Angaben zu 'Domestic Gross', 'Worldwide Gross' und 'Production Budget' haben, sodass wir in diesem Falle immer von dem aktuellen Umrechnungskurs ausgehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "exchangeRates =  requests.get(\"https://api.ratesapi.io/api/latest?base=USD\").json()\n",
    "\n",
    "def exchange(cellInput):\n",
    "    currency    = ''.join([i for i in cellInput if not i.isdigit()])\n",
    "    money       = int(''.join([i for i in cellInput if  i.isdigit()]))\n",
    "    \n",
    "    if currency != '$':\n",
    "        return int( round( money / exchangeRates['rates'][currency],0))\n",
    "    else: \n",
    "        return money\n",
    "        \n",
    "        \n",
    "df['Production Budget'] = df['Production Budget'].apply(exchange)\n",
    "df['Domestic Gross'] = df['Domestic Gross'].apply(exchange)\n",
    "df['Worldwide Gross'] = df['Worldwide Gross'].apply(exchange)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Geldbeträge sollten nun umgerechnet sein und werden für unseren Beispielfilm wie folgt angezeigt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['tt1634121'][['Domestic Gross','Worldwide Gross','Production Budget']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Umwandlung von Strings zu Listen <a name=\"2.5DirectorExtraktion\"></a>\n",
    "Da die Regisseure, Autoren und Genres durch Kommata getrennt in dem Datensatz vorliegen, wollen wir diese trennen und in einer Liste speichern, um eine einzelne Betrachtung dieser zu ermöglichen. Doch vorab schauen wir uns wieder einen Beispieldatensatz an: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['tt0491162'][['Director', 'Genre', 'Writer']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Regisseure, Autoren und Genres werden folgend getrennt und als Liste abgelegt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Director'] = df['Director'].str.split(\", \") \n",
    "df['Genre'] = df['Genre'].str.split(\", \") \n",
    "\n",
    "df['Writer']= df['Writer'].str.replace(', ', ',').str.replace(' ,',',')\n",
    "df['Writer'] = df['Writer'].str.split(\",\") \n",
    "\n",
    "df.loc['tt0491162'][['Director', 'Genre', 'Writer']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Integer Dimensionen bestimmen   <a name=\"2.6DimensionType\"></a>\n",
    "Um im Anschluss Berechnungen durchzuführen, werden alle Dimensionen mit potenziellen Integer/Float Werten in eine Numeric Dimension umgewandelt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integerColumns = [    'Runtime', \n",
    "                      'Worldwide Gross', \n",
    "                      'imdbRating',\n",
    "                      'imdbVotes', \n",
    "                      'Production Budget', \n",
    "                      'Domestic Gross',\n",
    "                      'Worldwide Gross', \n",
    "                      'Metascore',\n",
    "                      'TomatoRating', \n",
    "                      'NominationAnother', \n",
    "                      'NominationBAFTA', \n",
    "                      'NominationEmmy',\n",
    "                      'NominationOscar', \n",
    "                      'NominationGoldenGlobe', \n",
    "                      'NominationGrammy',\n",
    "                      'NominationTeenChoiceAward', \n",
    "                      'NominationVESAward', \n",
    "                      'NominationYoungArtistAwards',\n",
    "                      'WinAnother', \n",
    "                      'WinBAFTA', \n",
    "                      'WinEmmy',\n",
    "                      'WinOscar', \n",
    "                      'WinGoldenGlobe', \n",
    "                      'WinGrammy',\n",
    "                      'WinTeenChoiceAward', \n",
    "                      'WinVESAward', \n",
    "                      'WinYoungArtistAwards']\n",
    "\n",
    "for x in integerColumns:\n",
    "    df[x] = pd.to_numeric(df[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Normierung der Bewertungsmetriken <a name=\"2.7RatingExtraktion\"></a>\n",
    "Unser Datensatz beinhaltet 3 Bewertungsmetriken. \n",
    "    \n",
    "    Metrik                      Werte-System\n",
    "    1. Rotten Tomato Rating     0 bis 100\n",
    "    2. IMDB Rating              0 bis 10\n",
    "    3. Metascore                0 bis 100\n",
    "    \n",
    "Die Rating Metriken werden in verschiedenen Werte-Systemen gehandhabt. Daher bedarf es einer  Vereinheitlichung der Daten. Anbei ein Beispiel von den aktuellen Werten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2][['TomatoRating','imdbRating','Metascore']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgend werden alle Metriken auf Werte >= 0 bis <= 1 normiert und auf maximal 2 Stellen nach dem Komma gerundet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['imdbRating'] = round(df['imdbRating']  / 10,2)\n",
    "df['Metascore']  = round(df['Metascore'] / 100,2)\n",
    "df['TomatoRating']  = round(df['TomatoRating'] / 100,2)\n",
    "\n",
    "df.iloc[2][['TomatoRating','imdbRating','Metascore']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Kalkulation von neuen Dimensionen   <a name=\"2.8CalculationOfDimensions\"></a>\n",
    "Um in einer Analyse mehr Informationen aus unseren Daten ziehen zu können, berechnen wir 4 neue Dimensionen:\n",
    "\n",
    "    1. SumWin           Die Summe aller Gewinne pro Film\n",
    "    2. SumNomination    Die Summe aller Nominierungen pro Film\n",
    "    3. Profit           Der Profit pro Film\n",
    "    4. ROI              Return on Investment pro Film\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SumWin'] = (df['WinAnother'] + \n",
    "                df['WinBAFTA'] + \n",
    "                df['WinEmmy'] + \n",
    "                df['WinGoldenGlobe'] + \n",
    "                df['WinGrammy'] + \n",
    "                df['WinOscar']+ \n",
    "                df['WinTeenChoiceAward'] + \n",
    "                df['WinVESAward']+ \n",
    "                df['WinYoungArtistAwards'])\n",
    "        \n",
    "df['SumNomination'] = ( df['NominationAnother'] + \n",
    "                        df['NominationBAFTA'] + \n",
    "                        df['NominationEmmy'] + \n",
    "                        df['NominationGoldenGlobe'] +\n",
    "                        df['NominationGrammy'] +\n",
    "                        df['NominationOscar']+ \n",
    "                        df['NominationTeenChoiceAward'] + \n",
    "                        df['NominationVESAward']+ \n",
    "                        df['NominationYoungArtistAwards'])\n",
    "        \n",
    "df['Profit'] = df['Worldwide Gross'] - df['Production Budget']\n",
    "df['ROI'] = df['Worldwide Gross'] / df['Production Budget']\n",
    "integerColumns += ['SumWin','SumNomination','Profit','ROI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Fehlende Rotten Tomato Bewertungen mit Regression bestimmen  <a name=\"2.9RegressionTomato\"></a>\n",
    "Leider fehlen Rotten Tomato Bewertungen für einige Filme. In diesem Absatz wird das Verfahren zur Bestimmung der fehlenden Rotten Tomato Bewertungen durch Regression beschrieben. Dafür betrachten wir zuerst die Anzahl an fehlenden Daten: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TomatoRating'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dafür möchten wir Dimensionen mit einer hohen Korrelation für die Regression finden. Um den Pairplot und die Heatmap nicht zu unübersichtlich zu gestalten, haben wir vorab die Dimensionen mit den höchsten Korrelationswerten herausgesucht und folgend gegenübergestellt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "heatMap_df = df[df['TomatoRating'].notnull()]\n",
    "columns = ['imdbRating', 'Metascore','TomatoRating']\n",
    "\n",
    "# Pairplot\n",
    "sns.set(style=\"ticks\")\n",
    "g= sns.pairplot(heatMap_df[columns] )\n",
    "g.fig.suptitle(\"Pairplot zur Bestimmung der Korrelationswerte\")\n",
    "plt.show()\n",
    "\n",
    "# Heatmap \n",
    "cm = np.corrcoef(heatMap_df[columns].values.T)\n",
    "\n",
    "sns.heatmap(cm, annot= True, \n",
    "            fmt = '.2f', \n",
    "            annot_kws = {'size' : 15}, \n",
    "            yticklabels= columns, \n",
    "            xticklabels= columns).set_title('Heatmap zur Bestimmung der Korrelationswerte')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist nicht besonders überraschend, dass die anderen beiden Bewertungsmetriken 'Metascore' und 'imdbRating' die höchste Korrelation aufweisen. Spitzenreiter ist dabei der 'Metascore' mit 0,91. Um die fehlenden Rotten Tomato Bewertungen zu ermitteln, haben wir verschiedene Verfahren, mit unterschiedlichen Hyperparameter-Optionen, sowie nur mit Metascore und Metascore + IMDB Rating, getestet und die R² / Score Trainingsdaten und R² / Score Testdaten verglichen. Die Ergebnisse schauen wie folgt aus: \n",
    "\n",
    "\n",
    "| Verfahren | X | Hyperparameter | R² / Score Trainingsdaten | R² / Score Testdaten | \n",
    "| --- | --- | --- | --- | --- | \n",
    "| Linear Regression | Metascore | --- | 0.820 | 0.816 | \n",
    "| Linear Regression | Metascore & imdbRating | --- | 0.836 | 0.838 | \n",
    "| --- | --- | --- | --- | --- | \n",
    "| DecisionTreeRegressor | Metascore | max_depth = 3 | 0.834 | 0.828 | \n",
    "| DecisionTreeRegressor | Metascore | max_depth = 4 | 0.843 | 0.838 | \n",
    "| DecisionTreeRegressor | Metascore | max_depth = 5 | 0.845 | 0.839 | \n",
    "| DecisionTreeRegressor | Metascore | max_depth = 6 | 0.846 | 0.838 |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| DecisionTreeRegressor | Metascore & imdbRating | max_depth = 3 | 0.836 | 0.830 | \n",
    "| DecisionTreeRegressor | Metascore & imdbRating | max_depth = 4 | 0.856 | 0.845 | \n",
    "| DecisionTreeRegressor | Metascore & imdbRating | max_depth = 5 | 0.867 | 0.851 | \n",
    "| DecisionTreeRegressor | Metascore & imdbRating | max_depth = 6 | 0.875 | 0.852 |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Polynominale Regresseion | Metascore | degree = 3 | 0.841 | 0.842 | \n",
    "| Polynominale Regresseion | Metascore | degree = 4 | 0.841 | 0.842 | \n",
    "| Polynominale Regresseion | Metascore | degree = 5 | 0.842 | 0.843 | \n",
    "| Polynominale Regresseion | Metascore | degree = 6 | 0.842 | 0.843 |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Polynominale Regresseion | Metascore & imdbRating  | degree = 3 | 0.866 | 0.865 | \n",
    "| Polynominale Regresseion | Metascore & imdbRating  | degree = 4 | 0.867 | 0.866 | \n",
    "|<font color=\"green\"><b> Polynominale Regresseion</b></font> | <font color=\"green\"><b> Metascore & imdbRating </b></font>|<font color=\"green\"><b> degree = 5</b></font> |<font color=\"green\"><b> 0.869 </b></font>| <font color=\"green\"><b>0.868 </b></font>| \n",
    "| Polynominale Regresseion | Metascore & imdbRating  | degree = 6 | 0.868 | 0.865 |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Die besten Scores haben wir mit der Polynominalen Regression und der Kombination aus den Werten Metascore & imdbRating erzielt. Zum einen haben wir mit einem R²Testscore von 0.868 den höchsten und zusätzlich nahe am 0.869 R²Trainingscore liegenden Wert gefunden. Im folgenden Code wird ein Test der Polynominalen Regression mit unterschiedlichen Graden durchgeführt. Im Durchschnitt erziehlt dabei eine Grad-Stufe von 5 einen Trainingswert von <b>0,869</b> und einen Testwert von <b>0,868</b>.  \n",
    "<br>\n",
    "Im folgenden Code Block ist das Testverfahren für die Polynominale Regression und der Kombination aus den Werten Metascore & imdbRating programmiert. Auf diese Weise wuden auch die anderen Verfahren getestet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "dfu = df[df['TomatoRating'].notnull()]\n",
    "X_ = dfu[['Metascore', 'imdbRating']]\n",
    "y_ = dfu['TomatoRating']\n",
    "\n",
    "# Erstellung des Result Dataframe\n",
    "result_df = pd.DataFrame(0.0, index= np.arange(2, 10),columns=['TrainScore','TestScore'])\n",
    "\n",
    "# 100 Testdurchläufe\n",
    "for testrun in range(1,100) :\n",
    "    # Erstellung der Test und Trainingsdaten\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, \n",
    "                                                        y_,  \n",
    "                                                        test_size = 0.3, \n",
    "                                                        shuffle = True)\n",
    "    \n",
    "    # Hyperparameter Degree der  Plynominalen Regression  von 2 bis 9                                                \n",
    "    for i in range(2,10): \n",
    "        quadratic = PolynomialFeatures(degree=i)\n",
    "        X_train_quad = quadratic.fit_transform(X_train)\n",
    "        X_test_quad = quadratic.fit_transform(X_test)\n",
    "        pr = LinearRegression()\n",
    "        pr.fit(X_train_quad, y_train)\n",
    "        \n",
    "        result_df.at[i, 'TrainScore'] =  result_df.loc[i]['TrainScore'] + pr.score(X_train_quad, y_train)\n",
    "        result_df.at[i, 'TestScore']  =  result_df.loc[i]['TestScore'] + pr.score(X_test_quad, y_test)\n",
    "\n",
    "# Berechnung des arithm. Mittel der Train- und Test-Scores\n",
    "result_df['TrainScore'] = result_df['TrainScore'] / testrun\n",
    "result_df['TestScore']  = result_df['TestScore']  / testrun\n",
    "\n",
    "# Plot \n",
    "ax = result_df.plot(figsize=(10,10))\n",
    "ax.set_xlabel('Grad-Stufen')\n",
    "ax.set_ylabel('R² Score in %')\n",
    "ax.set_title('Train und Testscore Vergleich der Polynominalen Regression bei unterschiedlichen Grad-Stufen')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch wenn der Unterschied zu den anderen Verfahren nicht sehr groß ist, entscheiden wir uns für die Bestimmung unserer fehlenden Rotten Tomato Bewertungen für die Polynominalen Regression, mit einer Grad-Stufe von 5 und der Dimensionen 'Metascores' sowie 'imdbRatings'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training mit allen Daten außer nan\n",
    "dfu = df[df['TomatoRating'].notnull()] \n",
    "X_ = dfu[['Metascore', 'imdbRating']]\n",
    "y_ = dfu['TomatoRating']\n",
    "       \n",
    "quadratic = PolynomialFeatures(degree=5)\n",
    "X_train_quad = quadratic.fit_transform(X_)\n",
    "pr = LinearRegression()\n",
    "pr.fit(X_train_quad, y_)\n",
    "\n",
    "# Ermittlung der Werte\n",
    "dfu = df[df['TomatoRating'].isnull()] \n",
    "X_quad = quadratic.fit_transform(dfu[['Metascore', 'imdbRating']])\n",
    "df.loc[dfu.index,'TomatoRating'] = [ '%.2f' % elem for elem in  pr.predict(X_quad) ]\n",
    "df['TomatoRating'] = pd.to_numeric(df['TomatoRating'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das folgende Ergebnis zeigt, dass alle Rotten Tomato Bewertungen bestimmt wurden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TomatoRating'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Datenanalyse <a name=\"3.Datenanalyse\"></a>\n",
    "Nachdem die Datenaufbereitung abgeschlossen ist, werden diese in diesem Kapitel analysiert. Anhand der Analyse kann man sich einen Überblick über den Datensatz verschaffen. Auch wenn es eine Vielzahl an weiteren Betrachtungen gibt, haben wir für diese Abgabe die folgenden Plots generiert.\n",
    "\n",
    "  1 [Verteilung der Filme pro Erscheinungsjahr](#3.1MovieReleaseYear)<br>\n",
    "    2 [Verteilung der Filme anhand ihrer Spieldauer](#3.2MovieRuntime)<br>\n",
    "    3 [Verteilung der Hauptgenre](#3.3GenreMovie)<br>\n",
    "    4 [Entwicklung der Einnahmen  und Ausgaben](#3.4BudgetGross)<br>\n",
    "    5 [Verteilung der Schauspieleranzahl](#3.5Actor)<br>\n",
    "    6 [Interaktives Diagramm](#3.6interactiveDiagram)<br>\n",
    "    7 [Bewertung der Akteure](#3.7meanRatingMainGenre)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Verteilung der Filme pro Erscheinungsjahr <a name=\"3.1MovieReleaseYear\"></a>\n",
    "In diesem Absatz wird die Verteilung der Anzahl der Filme pro Erscheinungsjahr in einem Histogramm dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_Years = df.groupby('Year')['Year'].count()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.bar(hist_Years.index,pd.Series(hist_Years).values,tick_label = hist_Years.index ,align='edge', width=1,edgecolor='black')\n",
    "plt.ylabel('Anzahl der Filme')\n",
    "plt.xlabel('Erscheinungsjahre')\n",
    "plt.title('Histogramm Filme pro Erscheinungsjahr')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Verteilung der Filme anhand ihrer Spieldauer <a name=\"3.2MovieRuntime\"></a>\n",
    "In diesem Absatz wird die Verteilung der Anzahl der Filme pro Spieldauer in einem Histogramm dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_RuntimeData = df.loc[(df['Runtime'] >= 75) & (df['Runtime'] < 150)]\n",
    "hist_Runtime = hist_RuntimeData.groupby('Runtime')['Runtime'].count()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.bar(hist_Runtime.index,pd.Series(hist_Runtime).values,tick_label = hist_Runtime.index ,align='edge', width=1,edgecolor='black')\n",
    "ax = plt.gca()\n",
    "for index, label in enumerate(ax.xaxis.get_ticklabels()):\n",
    "    if (index % 5) != 0:\n",
    "        label.set_visible(False)\n",
    "plt.ylabel('Anzahl der Filme')\n",
    "plt.xlabel('Film-Spielzeit in Minuten')\n",
    "plt.title('Histogramm Film-Spielzeit Verteilung')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Verteilung der Hauptgenre <a name=\"3.3GenreMovie\"></a>\n",
    "In diesem Absatz wird die Verteilung der Hauptgenre in einem Balkendiagramm dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "df_grouped = df.groupby(df.Genre.map(lambda x: x[0]))\n",
    "df_grouped['Genre'].count().sort_values().plot(kind = 'barh')\n",
    "plt.title('Film-Verteilung der Haupt-Genres')\n",
    "plt.xlabel('Anzahl der Filme')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Entwicklung der Einnahmen  und Ausgaben <a name=\"3.4BudgetGross\"></a>\n",
    "In diesem Absatz wird das durchschnittliche Produktions-Budget und die durchschnittlichen Inland- und Gesamteinnahmen in einem Liniendiagramm gegenübergestellt. Man kann erkennen, dass sich die Gesamteinnahmen ab ca. 1988 von den Inlandseinnahmen abheben. Im Jahr 2019 haben die Gesamteinnahmen ihren Peak erreicht und sich im Vergleich zu 1980 mehr als verdreifacht, wobei sich das Budget in diesem Zeitraum etwas mehr als verdoppelt hat.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "mean_DF = pd.DataFrame(df.groupby('Year')['Production Budget'].mean())\n",
    "mean_DF['Domestic Gross'] = df.groupby('Year')['Domestic Gross'].mean()\n",
    "mean_DF['Worldwide Gross']= df.groupby('Year')['Worldwide Gross'].mean()\n",
    "mean_DF = mean_DF / 1000000\n",
    "ax = mean_DF.plot()\n",
    "ax.set_xlabel('Jahr')\n",
    "ax.set_ylabel('US Doller in Millionen')\n",
    "ax.set_title('Durchschnittliche Kosten und Einnahmen pro Jahr')\n",
    "plt.xticks( range(1980,2020,1), rotation = 90)\n",
    "plt.yticks( range(0,250,25))\n",
    "plt.grid()\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Verteilung der Schauspieleranzahl<a name=\"3.5Actor\"></a>\n",
    "Für die Klassifizierung im kommenden Kapitel ist es interessant zu wissen, wieviele Schauspieler in Filmen vorkommen. Diese Anzahl wird später die Dimensionen unseres binär Vectorraumes stark beeinflussen. Im folgenden Plot ist die Verteilung sichtbar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_Actors = pd.DataFrame(df['Actors'].str.len(), index = df.index) \n",
    "\n",
    "max = df['Actors'].str.len().max()\n",
    "binsRange = list( range(0,240,20)) + [max]\n",
    "binNames = [\"(0, 20]\",   \"(20, 40]\",   \"(40, 60]\",   \"(60, 80]\",  \"(80, 100]\",\n",
    "            \"(100, 120]\", \"(120, 140]\", \"(140, 160]\", \"(160, 180]\", \"(180, 200]\",\n",
    "            \"(200, 220]\", \"(220, \"+str(max)+\"]\"]\n",
    "\n",
    "bins = pd.cut(hist_Actors['Actors'], binsRange )\n",
    "hist_Actors = hist_Actors.groupby(bins)['Actors'].agg(['count', 'sum'])\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.bar(binNames,hist_Actors['count'].values,align='center', width=1,edgecolor='black')\n",
    "\n",
    "plt.ylabel('Anzahl der Filme')\n",
    "plt.xlabel('Spannweiten der Schauspieleranzahl')\n",
    "plt.title('Verteilung der Schauspieleranzahl')\n",
    "plt.xticks(  rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Interaktives Diagramm <a name=\"3.6interactiveDiagram\"></a>\n",
    "Für diesen Absatz haben wir ein interaktives Diagramm entwickelt, mit welchem man die Filmdaten analysieren kann. Der Code für die Erstellung ist aufgrund seiner Größe in dem Source.py Script ausgelagert. Für das Diagramm kann die X-Achse, Y-Achse und Einfärbung der Punkte selbst gewählt werden. Wenn man über die Punkte hovert, erkennt man den Namen, das Erscheinungsjahr sowie den jeweils eingefärbten Wert des Filmes. \n",
    "\n",
    "Vorgeschlagene Setups: \n",
    "\n",
    "| X-Achse | Y-Achse | Einfärbung | Beschreibung | \n",
    "| :-- | :-- | :-- | :-- | \n",
    "| eine der 3 Bewertungsmetriken | eine weitere Bewertungsmetrik | Preisgewinne Gesamt | Man kann erkennen, dass die Gewinner von z.b. Oscars im Regelfall hohe Bewertungen erhalten haben. | \n",
    "| eine der 3 Bewertungsmetriken | eine weitere Bewertungsmetrik | Produktions-Budget | Auch wenn die einzelnen Filme mit dem höchsten Budget gute Bewertungen erhalten haben, ist die Masse recht gut verteilt. Man scheint also nicht direkt von dem Budget auf die Beliebheit des Filmes schliessen zu können. | \n",
    "| Profit | eine der 3 Bewertungsmetriken | eine der Gewinn Metriken | Der finanzielle Profit eines Filmes scheint nicht im Zusammenhang mit der Anzahl an gewonnen Preisen zu stehen. | \n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Funktioniert mit BokehJS 1.2.0 unter Port: 8888\n",
    "from source import loadGraphic\n",
    "from bokeh.plotting import show\n",
    "show(loadGraphic(df,integerColumns))\n",
    "#show(loadGraphic(df[df['Title'] != 'Paranormal Activity'],integerColumns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Bewertung der  Akteure<a name=\"3.7meanRatingMainGenre\"></a>\n",
    "Für diesen Absatz haben wir eine interaktive Oberfläche entwickelt, welche die Top 10 der Dimensionen Hauptdirector, Hauptactor, Hauptgenre sowie den Title der Filme in einem Diagramm darstellt. Die Sortierung der gewählten Dimensionen kann einzeln anhand der Metriken TomatoRating, imdbRating und Metascore oder nach dem Durchschnitt dieser erfolgen. Der Bewertungszeitraum kann dabei variabel bestimmt werden.\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source import loadGraphic2\n",
    "loadGraphic2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Klassifizierung der Filmbeliebtheit <a name=\"4predictionMovie\"></a>\n",
    "In diesem Kapitel wollen wir nun versuchen, zukünftige Filme anhand von Schauspielern, Genre, Regisseure, Autoren und der Produktionsfirma in die Beliebtheits-Kategorien \"Schlechter Film\", \"Durchschnittlicher Film\" und \"Guter Film\" zu klassifizieren. Dadurch könnte schon vor der Produktion eines Filmes bestimmt werden, ob dieser vom Publikum gut angenommen werden wird. Dabei gehen wir in den folgenden Schritten vor: \n",
    "\n",
    "  1. [Bestimmung der Klassen](#4.1createClasses)\n",
    "  2. [One Hot Encoding](#4.2classefier)\n",
    "  3. [Klassifizierung und Ergebnisse](#4.3classefier)\n",
    "  4. [Reduktion der Dimensionen](#4.4dimensionReduction)  \n",
    "  5. [Ein Versuch mit Regression](#4.5tryRegression)   \n",
    "  6. [Ergebnis](#4.6result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Bestimmung der Klassen <a name=\"4.1createClasses\"></a>\n",
    "Wir haben uns überlegt wie wir die 3 Kategorien \"Schlechter Film\", \"Durchschnittlicher Film\" und \"Guter Film\" am Besten für unsere Daten bestimmen. Da die Beliebtheit eines Filmes mit den 3 Metriken Metascore, IMDB Rating und Rotten Tomato Rating ausgedrückt wird, nehmen wir diese zur Grundlage. \n",
    "\n",
    "In diesen Skalen kategorisierten wir jeweils die Werte wie folgt: \n",
    "\n",
    "| Werte des Ratings | Kategorie | Anzahl der Filme | \n",
    "| :-- | :-- | --: | \n",
    " | <= 25% Quantil | Schlechter Film | ~1126 | \n",
    " | >= 75% Quantil | Guter Film |  ~1126 |\n",
    " | der Rest | Durchschnittlicher Film | ~2253 |\n",
    "   \n",
    "\n",
    "Die folgenden Plots beschreiben die Verteilung der einzelnen Metrik.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source import addSubPlot\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "ax1 = plt.subplot(212)\n",
    "ax2 = plt.subplot(221)\n",
    "ax3 = plt.subplot(222)\n",
    "\n",
    "ax1.set( ylabel='Relative Frequenz der Ratings')\n",
    "ax2.set( ylabel='Relative Frequenz der Ratings')\n",
    "fig.suptitle('Relative Bewertungsverteilung der Scores')\n",
    "ratingQuantile = {}\n",
    "ratingQuantile['Metascore'] = addSubPlot('Metascore', ax1,df)\n",
    "ratingQuantile['imdbRating'] = addSubPlot('imdbRating', ax3,df)\n",
    "ratingQuantile['TomatoRating'] = addSubPlot('TomatoRating', ax2,df)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 One Hot Encoding <a name=\"4.2classefier\"></a>\n",
    "Für die Klassifizierung wird ein binärer Vektorraum erstellt, welcher alle  Genre-, Schauspieler-, Autoren-, Produktionsfirma- und Regisseur-Einträge in Dimensionen umwandelt. Pro Film wird das Vorkommen der jeweiligen Akteure mit 1 versehen. Alle anderen erhalten eine 0. Folgend werden die Funktionen für die Umsetzung beschrieben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Erstellung  eines One Hot Encoding Dataframe von Genre, Schauspielern, Autoren oder Regisseur\n",
    "# Durch den Parameter n können die Top n Vertreter einer Dimension gewählt werden\n",
    "def get_one_hot_encodet(df, dimensionName, n = 1):\n",
    "    # Da ein Schauspieler in einerm anderen Film auch Autor sein kann, wird jedem Eintrag der \n",
    "    # Dimensionstitel angehangen\n",
    "    prefix = dimensionName + '_'\n",
    "    \n",
    "    # Es wird eine flache Liste mit allen top n der Dimension erstellt\n",
    "    all_dimension_entry_liste = list(map(lambda x: list(set(x))[:n] , df[dimensionName]))\n",
    "    flat_list = list(set([item for sublist in all_dimension_entry_liste for item in sublist]))\n",
    "    \n",
    "    # Es wird ein DataFrame erstelt, dessen Dimensionen aus allen \n",
    "    # n unique Einträgen der eingehenden Dimension besteht. Jeses Vorkommen wird mit 1 beschrieben\n",
    "    all_dimension_entry_df = pd.DataFrame()\n",
    "    seriesListe = list(map(lambda x: pd.Series(1, index = list(set(x))[:n] ) , df[dimensionName]))\n",
    "    all_dimension_entry_df  = all_dimension_entry_df .append(seriesListe) \n",
    "    all_dimension_entry_df = all_dimension_entry_df.add_prefix(prefix)\n",
    "    all_dimension_entry_df = all_dimension_entry_df.set_index([pd.Index( df.index.tolist())])\n",
    "    return all_dimension_entry_df, flat_list\n",
    "\n",
    "# Die Funktion erstellt pro Produktionsfirma eine Dimension und beschreibt das Vorkommen mit 1\n",
    "def get_one_hot_encodet_Production(df):\n",
    "    #Alle Produktionen werden in Dimensionen umgewandelt. Jeses Vorkommen pro Film wird mit 1 beschrieben\n",
    "    productionDF_ohe = pd.get_dummies(df['Production'],prefix='Production_')\n",
    "    # Es wird eine flache Liste mit allen top n der Dimension erstellt\n",
    "    flat_list = list(set(df['Production'].tolist()))\n",
    "    return productionDF_ohe, flat_list\n",
    "\n",
    "# Funktion fügt eine Liste an eingehenden Dataframes zu einem Dataframe zusammen und\n",
    "# füllt alle Werte die keine 1 haben mit 0 aus\n",
    "def mergeDataFrames(data_frames):\n",
    "    mergedDataFrame=  reduce(lambda  left,right: pd.merge(left,right,left_index=True, right_index=True), data_frames)\n",
    "    return   mergedDataFrame.fillna(0)\n",
    "\n",
    "# gemäß der Vorab besteimmten Quantile pro Bewertungsmetrik, wird in dieser Funktion dem input Dataframe\n",
    "# die Kategorie zugewiesen\n",
    "def addCategorys(df_input,df, metric,quantileList):\n",
    "    conditions = [\n",
    "    (df[metric] >= quantileList[metric][1]),\n",
    "    (df[metric] <= quantileList[metric][0])]\n",
    "    \n",
    "    choices = ['Guter Film', 'Schlechter Film']\n",
    "    \n",
    "    df_input['Category'] = np.select(conditions, choices, default='Durchschnittlicher Film')\n",
    "    return df_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem die Funktionen definiert wurden, wenden wir diese im folgenden Schritt an. Für die Ergebnisauswertung der Klassifizierung haben wir die maximale Anzahl an Autoren, Genres, Schauspielern, Produktionsfirmen und Regisseuren genutzt. Wie in [3.5 Verteilung der Schauspieleranzahl](#3.5Actor) dargestellt, haben die Schauspieler eine Maximalanzahl von 475 pro Film. Daher würde die Ausführung des folgenden Codes bis zu einer Minute dauern. Um den Prozess etwas zu beschleunigen, wählen wir in diesem Beispiel vier Schauspieler, jeweils eine/n Regisseur, Produktionsfirma und Autor sowie das Hauptgenre aus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genreDF_ohe, genreList = get_one_hot_encodet(df, 'Genre')\n",
    "actorsDF_ohe, actorList = get_one_hot_encodet(df, 'Actors',4)\n",
    "directorsDF_ohe, directorList = get_one_hot_encodet(df, 'Director')\n",
    "writersDF_ohe, writersList = get_one_hot_encodet(df, 'Writer')\n",
    "productionDF_ohe, productionList = get_one_hot_encodet_Production(df)\n",
    "\n",
    "df_merged = mergeDataFrames([genreDF_ohe, directorsDF_ohe,writersDF_ohe, actorsDF_ohe, productionDF_ohe  ])\n",
    "df_merged = addCategorys(df_merged , df , 'Metascore',ratingQuantile)\n",
    "df_merged.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Klassifizierung und Ergebnisse <a name=\"4.3classefier\"></a>\n",
    "Da es sich um ein Klassifizierungsproblem handelt, haben wir für diesen Absatz die Klassifikationsverfahren BernoulliNB, MultinomialNB, GaussianNB, DecisionTree und KNN der Sklearn-Bibliothek mit verschiedenen Hyperparametern getestet. Der Datensatz für den Test setzt sich wie folgt zusammen:\n",
    "\n",
    "|  Attribut |  max n pro Film  | Anzahl an Dimensionen | \n",
    "| --- | --- | --- | \n",
    "| Actors | 475  | 148617 |\n",
    "| Autoren|   10 | 4256  |\n",
    "| Director | 10 | 2138  |\n",
    "| Producer | 10 | 522   |\n",
    "| Genre  | 10 |    21   |\n",
    "|   | <b>Gesamt</b>  | <b>155554</b> |\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "|  ---  | Training | Test | Gesamt |\n",
    "| --- | --- |--- |--- |\n",
    "| Datensätze | 3154 | 1353 | <b>4507</b> |\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Zur Auswertung der Tests wurden die Metriken: \n",
    "\n",
    "<b>Accuracy: </b> Prozentualer Anteil aller richtig gefundenen Kategorien.<br>\n",
    "<b>Precision: </b> Wieviele der als \"Schlechter Film\" klassifizierten Filme gehören tatsächlich der Kategorie \"Schlechter Film\" an? <br>\n",
    "<b>Recall: </b> Wieviele der zu findenden Kategorien \"Schlechter Film\" haben wir tatsächlich gefunden?  <br>\n",
    "<b>F1Score: </b> Gewichteter Durchschnitt von Precision und Recall.  <br>\n",
    "<br>\n",
    "Die Ergebnisse sind in den folgenden Tabellen dargestellt, wobei anhand des Metascore getestet wurde. Das jeweils beste Ergebnis pro Klassifizierungsverfahren wird <b>bold</b> dargestellt. Um einen besseren Überblick zu erhalten, wurden jeweils der beste F1-Score der Kategorien <i>Schlecht</i>, <i>Durchschnitt</i> und <i>Gut</i> <font color=\"green\">grün</font> gefärbt. \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<b><u>BernoulliNB</u></b>\n",
    "<br>\n",
    "\n",
    " |Hyperparameter | Accuracy | Schlecht Precision | Schlecht Recall | Schlecht F1 | Durchschnitt Precision | Durchschnitt Recall | Durchschnitt F1 | Gut Precision | Gut Recall | Gut F1 |\n",
    " |--- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    " |alpha = 0.1 | 0.438 | 0.387 | 0.604 |\t<font color=\"green\"><b>0.471</b></font>| 0.541 |\t0.315 |\t0.398 |\t0.410 | 0.512 |\t<font color=\"green\"><b>0.455</b></font> |\n",
    "| alpha = 0.2 | 0.460 | 0.404 |\t0.514 |\t0.452 | 0.507 |\t0.446 | 0.475 |\t0.455 |\t0.427 |\t0.440 |\n",
    "| alpha = 0.3 | 0.466 | 0.364 |\t0.330 | 0.346 | 0.497 |\t0.642 |\t0.560 |\t0.485 |\t0.272 |\t0.349 |\n",
    "| alpha = 0.4 | 0.486 | 0.458 |\t0.257 |\t0.329 | 0.500 |\t0.774 |\t0.607 |\t0.425 |\t0.175 |\t0.248 |\n",
    "| alpha = 0.5 | 0.464 | 0.391 |\t0.123 |\t0.187 | 0.467 |\t0.864 |\t0.606 |\t0.529 |\t0.124 |\t0.200 |\n",
    "| <big><b>alpha = 0.6 </b></big>| <big><b>0.523</b></big>| <big><b>0.389</b></big> |\t<big><b>0.1 </b></big>|\t<big><b>0.132 </b></big>| <big><b>0.512 </b></big>|\t<big><b>0.943 </b></big>|\t<big><b>0.659</b></big> |\t<big><b>0.586 </b></big>|\t<big><b>0.105 </b></big>|\t<big><b>0.178 </b></big>|\n",
    "| alpha = 0.7 | 0.484 | 0.381 |\t0.048 |\t0.086 | 0.485 |\t0.946 |\t0.641 |\t0.561 |\t0.062 |\t0.112 |\n",
    "| alpha = 0.8 | 0.467 | 0.205 |\t0.022 |\t0.040 | 0.468 |\t0.953 |\t0.628 |\t0.808 |\t0.059 |\t0.110 |\n",
    "| alpha = 0.9 | 0.500 | 0.385 |\t0.014 |\t0.028 | 0.501 |\t0.972 |\t0.661 |\t0.484 |\t0.046 |\t0.084 |\n",
    "| alpha = 1.0 | 0.499 | 0.182 |\t0.006 |\t0.012 | 0.500 |\t0.985 |\t<font color=\"green\"><b>0.663</b></font> |\t0.667 |\t0.023 |\t0.045 |\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Bei der BernoulliNB Methode kann man gut erkennen, dass die zwei \"Ränder\" <i>Gut</i> und <i>Schlecht</i> bei einem geringen Alpha-Wert am Besten performen.  Umso höher der Alpha-Wert steigt, umso stärker wird der F1-Score der <i>Durchschnitt</i> Kategorie. Mit einem Aplpha-Wert von 1.0 konnte sogar ein Recall von 0.985 erziehlt werden.  Obwohl der Gesamtscore mit einem Alpha von 0.6 am höchsten liegt, sollte man die F1 Scores aller Kategorien betrachten. Kategorie <i>Schlecht</i> und <i>Gut</i> haben bei diesem Score sehr schlechte Werte im Verhältnis zu <i>Durchschnitt</i>. Gegebenenfalls könnte man sich für einen etwas schlechteren Gesamtscore entscheiden, wobei alle Kategorien etwas besser ausgleichen wie bei Aplha 0.4.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<b><u>MultinomialNB</u></b>\n",
    "<br>\n",
    "\n",
    "\n",
    "| Hyperparameter | Accuracy | Schlecht Precision | Schlecht Recall | Schlecht F1 | Durchschnitt Precision | Durchschnitt Recall | Durchschnitt F1 | Gut Precision | Gut Recall | Gut F1 |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| alpha = 0.1 | 0.442 | 0.415\t| 0.636\t| 0.503\t| 0.532\t| 0.257\t| 0.346\t| 0.415\t| 0.584\t| 0.485|\n",
    "| alpha = 0.2 | 0.441\t| 0.394\t| 0.617\t| 0.481\t| 0.557\t| 0.254\t| 0.349\t| 0.424\t| 0.618\t| 0.503|\n",
    "| alpha = 0.3 | 0.444\t| 0.42\t| 0.581\t| 0.488\t| 0.523\t| 0.252\t| 0.34\t| 0.422\t| 0.646\t| 0.511|\n",
    "| alpha = 0.4 | 0.445\t| 0.412\t| 0.592\t| 0.486\t| 0.517\t| 0.298\t| 0.379\t| 0.423\t| 0.569\t| 0.485|\n",
    "| alpha = 0.5 | 0.477\t| 0.439\t| 0.609\t| <font color=\"green\"><b>0.510</b></font>\t| 0.55\t| 0.333\t| 0.415\t| 0.455\t| 0.605\t| <font color=\"green\"><b>0.519</b></font>|\n",
    "| alpha = 0.6 | 0.466\t| 0.441\t| 0.561\t| 0.494\t| 0.517\t| 0.357\t| 0.423\t| 0.442\t| 0.556\t| 0.492|\n",
    "| alpha = 0.7 | 0.480\t| 0.452\t| 0.488\t| 0.469\t| 0.533\t| 0.425\t| 0.473\t| 0.447\t| 0.569\t| 0.501|\n",
    "| alpha = 0.8 | 0.470\t| 0.447\t| 0.499\t| 0.472\t| 0.532\t| 0.436\t| 0.479\t| 0.412\t| 0.506\t| 0.454|\n",
    "| <big><b>alpha = 0.9</b></big> | <big><b>0.483</b></big>\t| <big><b>0.428</b></big>\t| <big><b>0.469</b></big>\t| <big><b>0.447</b></big>\t| <big><b>0.534</b></big>\t| <big><b>0.458</b></big>\t| <big><b><font color=\"green\"><b>0.493</b></font>\t| <big><b>0.463</b></big>\t| <big><b>0.538</b></big>\t| <big><b>0.497</b></big>|\n",
    "| alpha = 1.0 | 0.476\t| 0.465\t| 0.447\t| 0.456\t| 0.523\t| 0.461\t| 0.49\t| 0.422\t| 0.538\t| 0.473|\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Bei dem MultinomialNB Verfahren kann man gut erkennen, dass die F1 Scores der Kategorien etwas besser ausgeglichen sind. Die \"Ränder\" <i>Schlecht</i> und <i>Gut</i> haben bei einem Alpha-Wert von 0.5 die besten F1 Ergebnisse erziehlt. <i>Durchschnitt</i> hat den besten F1 Score bei einem Alpha-Wert von 0.9. Dieser hat sich durch die Höhe von Alpha leicht verbessern können.  Generell kann man hier aber im Vergleich zu dem BernoulliNB erkennen, dass die Werte durch alle 3 Kategoreien ausgeglichener sind. Es sind keine Werte extrem hoch, wenn andere extrem niedrig sind. Als das beste Gesamtergebnis betrachten wir das Vorletzte mit einem Alpha-Wert von 0.9.\n",
    "<br>\n",
    "<br>\n",
    "<b><u>ComplementNB</u></b>\n",
    "<br>\n",
    "\n",
    "| Hyperparameter | Accuracy | Schlecht Precision | Schlecht Recall | Schlecht F1 | Durchschnitt Precision | Durchschnitt Recall | Durchschnitt F1 | Gut Precision | Gut Recall | Gut F1 |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| alpha = 0.1 | 0.434\t| 0.38\t| 0.544\t| 0.448\t| 0.545\t| 0.32\t| 0.403\t| 0.399\t| 0.543\t| 0.46 |\n",
    "| alpha = 0.2 | 0.437\t| 0.39\t| 0.557\t| 0.459\t| 0.528\t| 0.267\t| 0.354\t| 0.427\t| 0.617\t| 0.505 |\n",
    "| alpha = 0.3 | 0.428\t| 0.38\t| 0.613\t| 0.469\t| 0.567\t| 0.265\t| 0.361\t| 0.393\t| 0.565\t| 0.463 |\n",
    "| alpha = 0.4 | 0.441\t| 0.371\t| 0.581\t| 0.453\t| 0.552\t| 0.265\t| 0.358\t| 0.44\t| 0.637\t| <font color=\"green\"><b>0.521</b></font> |\n",
    "| alpha = 0.5 | 0.444\t| 0.41\t| 0.605\t| <font color=\"green\"><b>0.489</b></font>\t\t| 0.553\t| 0.276\t| 0.368\t| 0.407\t| 0.611\t| 0.489 |\n",
    "| alpha = 0.6 | 0.429\t| 0.419\t| 0.578\t| 0.485\t| 0.516\t| 0.272\t| 0.356\t| 0.378\t| 0.584\t| 0.459 |\n",
    "| alpha = 0.7 | 0.443\t| 0.395\t| 0.571\t| 0.467\t| 0.563\t| 0.322\t| 0.41\t| 0.397\t| 0.549\t| 0.46 |\n",
    "| alpha = 0.8 | 0.449\t| 0.387\t| 0.524\t| 0.445\t| 0.534\t| 0.343\t| 0.418\t| 0.431\t| 0.574\t| 0.492 |\n",
    "| alpha = 0.9 | 0.444\t| 0.434\t| 0.55\t| 0.485\t| 0.494\t| 0.309\t| 0.38\t| 0.414\t| 0.578\t| 0.483 |\n",
    "| <big><b>alpha = 1.0</b></big> | <big><b>0.460</b></big>\t| <big><b>0.427</b></big>\t| <big><b>0.562</b></big>\t| <big><b>0.486</b></big>\t| <big><b>0.573</b></big>\t| <big><b>0.339</b></big>\t| <big><font color=\"green\"><b>0.426</b></font></big>\t| <big><b>0.401</b></big>\t| <big><b>0.588</b></big>\t| <big><b>0.477</b></big> |\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Das ComplementNB Verfahren ähnelt sehr dem MultinomialNB. Auch hier kann man erkennen, dass die Werte durch alle 3 Kategoreien ausgeglichener als bei dem BernoulliNB sind. Es sind keine Werte extrem hoch, wenn andere extrem niedrig sind. Als das beste Gesamtergebnis betrachten wir das Letzte mit einem Alpha-Wert von 1.0.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<b><u>DecisionTree mit Entropy</u></b>\n",
    "<br>\n",
    "\n",
    "| Hyperparameter | Accuracy | Schlecht Precision | Schlecht Recall | Schlecht F1 | Durchschnitt Precision | Durchschnitt Recall | Durchschnitt F1 | Gut Precision | Gut Recall | Gut F1 |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| entropy depth = 1  | 0.494\t|0.0  |0.0  |0.0  |0.494  |\t1.0  |\t0.661|0.0\t|0.0\t|0.0|\n",
    "| entropy depth = 2  | 0.501\t|0.0  |0.0  |0.0  |0.501  |\t1.0  |\t0.668|0.0\t|0.0\t|0.0|\n",
    "| entropy depth = 3  | 0.477\t|1.0  |0.003|0.006|\t0.478 |\t0.988|\t0.644|0.333\t|0.012\t|0.022|\n",
    "| entropy depth = 4  | 0.5\t|0.75 |0.008|0.017|\t0.499 |\t0.979|\t0.661|0.533\t|0.049\t|0.089|\n",
    "| entropy depth = 5  | 0.458\t|0.6  |0.008|0.016|\t0.465 |\t0.954|\t0.625|0.25\t|0.033\t|0.058|\n",
    "| entropy depth = 6  | 0.477\t|0.5  |0.039|<font color=\"green\"><b>0.073</b></font>|\t0.484 |\t0.892|\t0.628|0.393\t|0.121\t|0.185|\n",
    "| <big><b>entropy depth = 7 </b></big> | <big><b>0.516\t</b></big>|<big><b>0.667</b></big>|<big><b>0.033</b></big>|<big><b>0.062</b></big>|\t<big><b>0.51  </b></big>|\t<big><b>0.973</b></big>|\t<big><font color=\"green\"><b>0.67 </b></font></big>|<big><b>0.619</b></big>\t|<big><b>0.084</b></big>\t|<big><b>0.148</b></big>|\n",
    "| entropy depth = 8  | 0.483\t|0.444|0.035|0.065|\t0.481 |\t0.969|\t0.643|0.613\t|0.052\t|0.096|\n",
    "| entropy depth = 9  | 0.481\t|0.619|0.036|0.068|\t0.487 |\t0.919|\t0.636|0.384\t|0.112\t|0.174|\n",
    "| entropy depth = 10 | 0.491|0.455|0.013|0.026|\t0.489 |\t0.926|\t0.64 |0.514\t|0.17\t|<font color=\"green\"><b>0.255</b></font>|\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Bei der DecisionTree mit Entrophy Methode kann man erkennen, dass bei depth = 1 und 2 zwar ein <i>Durchschnitt</i> Recall  von 1 erzielt wurde (Das bedeudet, wir haben alle zu findenden <i>Durchschnitt</i> Kategorien gefunden), aber unsere Treffsicherheit (Precision) insgesamt nur bei ca 0.5 lag. Daraus resultiert, dass nahezu alle unsere gefundenen Kategorien <i>Durchschnitt</i> waren. Die \"Ränder\" <i>Schlecht</i> und <i>Gut</i> haben durchgängig schlechte Ergebnisse geliefert. \n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<b><u>DecisionTree mit Gini</u></b>\n",
    "<br>\n",
    "\n",
    "| Hyperparameter | Accuracy | Schlecht Precision | Schlecht Recall | Schlecht F1 | Durchschnitt Precision | Durchschnitt Recall | Durchschnitt F1 | Gut Precision | Gut Recall | Gut F1 |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| gini depth = 1  |0.474|0.0\t|0.0\t|0.0\t|0.474\t|1.0\t|0.643\t|0.0\t|0.0\t|0.0  |\n",
    "| gini depth = 2  |0.483|0.0\t|0.0\t|0.0\t|0.486\t|0.948\t|0.643\t|0.432\t|0.09\t|0.148| \n",
    "| gini depth = 3  |0.494|1.0\t|0.006\t|0.011\t|0.492\t|0.998\t|0.659\t|0.778\t|0.021\t|0.04 |\n",
    "| gini depth = 4  |0.503|0.192\t|0.015\t|0.028\t|0.506\t|0.968\t|0.664\t|0.643\t|0.052\t|0.097|\n",
    "| gini depth = 5  |0.486|0.6\t|0.009\t|0.017\t|0.481\t|0.977\t|0.645\t|0.632\t|0.067\t|0.122|\n",
    "| gini depth = 6  |0.503|0.643\t|0.026\t|0.05\t|0.5\t|0.974\t|0.661\t|0.575\t|0.068\t|0.121|\n",
    "| gini depth = 7  |0.492|0.5\t|0.045\t|0.082\t|0.487\t|0.928\t|0.639\t|0.553\t|0.128\t|<font color=\"green\"><b>0.208</b></font>\t|\n",
    "| gini depth = 8  |0.475|0.488\t|0.057\t|<font color=\"green\"><b>0.102</b></font>\t|0.472\t|0.946\t|0.63\t|0.523\t|0.065\t|0.116|\n",
    "| gini depth = 9  |0.489|0.471\t|0.024\t|0.045\t|0.488\t|0.959\t|0.647\t|0.509\t|0.08\t|0.138|\n",
    "| <big><b>gini depth = 10</b></big> |<big><b>0.508</b></big>|<big><b>0.48</b></big>\t|<big><b>0.036</b></big>\t|<big><b>0.067</b></big>|<big><b>0.509</b></big>|<big><b>0.962</b></big>|<big><font color=\"green\"><b>0.665</b></font></big>\t|<big><b>0.522</b></big>\t|<big><b>0.07</b></big>\t|<big><b>0.124</b></big>|\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Bei der DecisionTree mit Gini Methode verhält es sich ähnlich der Entropy Variante. Die \"Ränder\" <i>Schlecht</i> und <i>Gut</i> haben durchgängig schlechte Ergebnisse geliefert, wobei der <i>Durchschnitt</i> alles nach \"oben\" reißt. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<b><u>KNN</u></b>\n",
    "<br>\n",
    "\n",
    "| Hyperparameter | Accuracy | Schlecht Precision | Schlecht Recall | Schlecht F1 | Durchschnitt Precision | Durchschnitt Recall | Durchschnitt F1 | Gut Precision | Gut Recall | Gut F1 |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| neighbors = 1   |0.316|\t1.0|\t0.005|\t<font color=\"green\"><b>0.011</b></font>|\t0.584|\t0.179|\t0.274|\t0.269|\t0.904|\t<font color=\"green\"><b>0.414</b></font>|\n",
    "| neighbors = 2   |0.429|\t1.0|\t0.003|\t0.006|\t0.463|\t0.759|\t0.575|\t0.325|\t0.284|\t0.303|\n",
    "| neighbors = 3   |0.473|\t0.0|\t0.0|\t0.0|\t0.478|\t0.919|\t0.629|\t0.418|\t0.143|\t0.213|\n",
    "|<big><b> neighbors = 4  </b></big> |<big><b>0.489</b></big>|\t<big><b>0.0</b></big>|\t<big><b>0.0</b></big>|\t<big><b>0.0</b></big>|\t<big><b>0.493</b></big>|\t<big><b>0.985</b></big>|\t<font color=\"green\"><b>0.657</b></font>|<big><b>\t0.259</b></big>|\t<big><b>0.02 </b></big>| <big><b> 0.037</b></big>|\n",
    "| neighbors = 5   |0.406|\t0.0|\t0.0|\t0.0|\t0.485|\t0.767|\t0.594|\t0.15 |\t0.142|\t0.146|\n",
    "| neighbors = 6   |0.387|\t0.0|\t0.0|\t0.0|\t0.496|\t0.666|\t0.569|\t0.176|\t0.248|\t0.206|\n",
    "| neighbors = 7   |0.381|\t1.0|\t0.003|\t0.005|\t0.477|\t0.709|\t0.57 |\t0.134|\t0.155|\t0.144|\n",
    "| neighbors = 8   |0.486|\t0.0|\t0.0|\t0.0|\t0.487|\t0.997|\t0.654|\t0.0\t |  0.0\t |  0.0  |\n",
    "| neighbors = 9   |0.479|\t0.0|\t0.0|\t0.0|\t0.481|\t0.991|\t0.648|\t0.231|\t0.009|\t0.017|\n",
    "| neighbors = 10  |0.48\t|   0.0|\t0.0|\t0.0|\t0.498|\t0.941|\t0.652|\t0.16 |\t0.036|\t0.059|\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Bei der KNN Methode hat sich die <i>Schlecht</i> Kategorie gar nicht entwickelt. Mit der Anzahl an Neighbors ist die Performance der <i>Gut</i> Kategorie immer schlechter geworden. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<b><u>GaussianNB</u></b>\n",
    "<br>\n",
    "\n",
    "| Hyperparameter | Accuracy | \n",
    "| --- | --- | \n",
    "| var_smoothing = 0.1 | 0.256\n",
    "| var_smoothing = 0.2 |0.254\n",
    "| var_smoothing = 0.3 |0.271\n",
    "| var_smoothing = 0.4 |0.259\n",
    "| var_smoothing = 0.5 |0.234\n",
    "| var_smoothing = 0.6 |0.239\n",
    "| var_smoothing = 0.7 |0.262\n",
    "| var_smoothing = 0.8 |0.256\n",
    "| var_smoothing = 0.9 |0.256\n",
    "| <big><b>var_smoothing = 1.0 </b></big>|<big><b>0.277</b></big>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Das GaussianNB Klassifizierungsverfahren hat durch und durch sehr schlecht abgeschnitten. Es wurden höchstens 27,7% aller zu findenden Klassen durch den Algorithmus richtig klassifiziert. Dies liegt weit unter den Ergebnissen der anderen Verfahren. \n",
    "<br>\n",
    "<br>\n",
    "Das Testverfahren ist in der Datei source.py als Funktion checkClassifikationMethods(df, 'BernoulliNB') einsehbar. In diesem Notebook kann der Test mit der Anweisung: \n",
    "<br><br>\n",
    "<font color=\"green\">from</font> source <font color=\"green\">import</font> checkClassifikationMethods<br>\n",
    "testResult = checkClassifikationMethods(df, 'BernoulliNB')\n",
    "<br><br>\n",
    "in einem Code Teil aufgerufen werden. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Reduktion der Dimensionen <a name=\"4.4dimensionReduction\"></a>\n",
    "Auch wenn der Unterschied minimal ist, konnte der beste Trainingsscore durch den BernoulliNB Classifier mit einem Alpha von 0.6 erzielt werden. Dennoch ist der Score mit 0.523 sehr schlecht und ist daher nicht wirklich aussagekräftig. Um zu untersuchen, ob das Ergebnis durch eine Reduktion der Dimensionen verbessert werden kann, haben wir erneut einen Test mit den Top 1 bis maximal 56 (Median) Schauspielern pro Film durchgeführt. Die Schauspieler sind nach ihrer Wichtigkeit (Haupt - Nebendarsteller) sortiert, sodass wir sicherstellen, dass die wichtigen n Hauptdarsteller unter den Schauspielern sind. Da der Test recht lang dauert, haben wir das Ergebnis in der folgenden Grafik dargestellt.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source import printf1ScoreByIncreasingDimensions\n",
    "printf1ScoreByIncreasingDimensions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anders als erwartet, bleibt die Accuracy durch eine Erhöhung der Dimensionsanzahl relativ gleich. In dem <i>F1 Score Entwicklung</i> Diagramm erkennt man, dass die <i>Schlecht</i> und <i>Gut</i> Kategorien mit der Anzahl an Dimensionen immer schlechter werden. Der <i>Durchschnitt</i> bleibt hingegen auf einem Level. Ein ähnliches Phenomän ist in dem <i>Recall Entwicklung</i> Diagramm zu sehen. Der einzige Unterschied ist, dass die Kategorie <i>Durchschnitt</i> eher steigt. Im <i>Precision Entwicklung</i> Diagramm ist keine klare Linie der <i>Schlecht</i> und <i>Gut</i> Kategorien ausmachbar. Grundsätzlich sind diese Werte aber höher als die der <i>Durchschnitt</i> Kategorie. In allen 3 Diagrammen ist die <i>Durchschnitt</i> Kategorie relativ stabil. <i>Schlecht</i> und <i>Gut</i> hingegen sind sehr unstabil. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Ein Versuch mit Regression <a name=\"4.5tryRegression\"></a>\n",
    "\n",
    "Ein weiterer Ansatz das Klassifizierungsproblem zu lösen, ist die Verwendung von Regression. Dabei ist die Idee, dass wir anhand von Regressionsverfahren versuchen die tatsächliche Bewertungsmetrik zu ermitteln. Den ermittelten Wert können wir im Anschluss, anhand der in Absatz [4.1 Bestimmung der Klassen](#4.1createClasses) beschriebenen Quantile, wieder in Kategorien einteilen. \n",
    "\n",
    "Dafür haben wir die Regressionsverfahren LinearRegression, DecisionTreeRegressor und LogisticRegression der Sklearn-Bibliothek mit verschiedenen Hyperparametern getestet. Leider konnten wir keine Polynominal- und Bayesian-Ridge Regression durchführen, da die Performance der beiden Verfahren so langsam war, dass selbst nach 1h noch kein Ergebnis erzielt wurde. \n",
    "<br>\n",
    "<br>\n",
    "Der Datensatz für den Test setzt sich wie folgt zusammen:\n",
    "\n",
    "|  Attribut |  max n pro Film  | Anzahl an Dimensionen | \n",
    "| --- | --- | --- | \n",
    "| Actors | 475  | 11558 |\n",
    "|  Autoren|  10     |   4256|\n",
    "| Director | 10 | 2138  |\n",
    "| Producer | 10 | 522   |\n",
    "| Genre  | 10 |    21   |\n",
    "|   | <b>Gesamt</b>  | <b>18495</b> |\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "|  ---  | Training | Test | Gesamt |\n",
    "| --- | --- |--- |--- |\n",
    "| Datensätze | 3154 | 1353 | <b>4507</b> |\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Zur Auswertung der Tests wurden die Metriken: \n",
    "<br>\n",
    "<br>\n",
    "<b>Für die Regression</b><br>\n",
    "<b>R² TrainScore:</b> Genauigkeit der Trainingsdaten <br>\n",
    "<b>R² TestScore:</b> Genauigkeit der Testdaten \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<b>Für die Klassifikation</b><br>\n",
    "<b>Accuracy: </b> Prozentualer Anteil aller richtig gefundenen Kategorien.<br>\n",
    "<b>Precision: </b> Wieviele der als \"Schlechter Film\" klassifizierten Filme gehören tatsächlich der Kategorie \"Schlechter Film\" an? <br>\n",
    "<b>Recall: </b> Wieviele der zu findenden Kategorien \"Schlechter Film\" haben wir tatsächlich gefunden?  <br>\n",
    "<b>F1Score: </b> Gewichteter Durchschnitt von Precision und Recall.  <br>\n",
    "<br>\n",
    "Die Ergebnisse sind in den folgenden Tabellen dargestellt, wobei anhand des Metascore getestet wurde. Das jeweils beste Ergebnis pro Klassifizierungsverfahren wird <b>bold</b> dargestellt. Um einen besseren Überblick zu erhalten, wurden jeweils der beste F1-Score der Kategorien <i>Schlecht</i>, <i>Durchschnitt</i> und <i>Gut</i> <font color=\"green\">grün</font> gefärbt. \n",
    "<br>\n",
    "\n",
    "<b>LinearRegression </b>\n",
    "<br>\n",
    "\n",
    "\n",
    "| R²TrainScore | R²TestScore | Accuracy| Schlecht Precision | Schlecht Recall | Schlecht F1 | Durchschnitt Precision | Durchschnitt Recall | Durchschnitt F1 | Gut Precision | Gut Recall | Gut F1 |\n",
    "| ---| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "|1.0 |0.202|0.525|0.166|0.528|0.252|0.863|0.511|0.642|0.25 |0.642|0.359|\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Mit der linearen Regression konnte eine Accuracy von 0,525 erreicht werden. Die Ränder <i>Gut</i> und <i>Schlecht</i> haben einen sehr geringen Recision Wert. \n",
    "<br>\n",
    "<br>\n",
    "<b>DecisionTreeRegressor </b>\n",
    "<br>\n",
    "\n",
    "\n",
    "| Hyperparameter | R²TrainScore | R²TestScore | Accuracy| Schlecht Precision | Schlecht Recall | Schlecht F1 | Durchschnitt Precision | Durchschnitt Recall | Durchschnitt F1 | Gut Precision | Gut Recall | Gut F1 |\n",
    "| :---:| ---| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| max_depth = 4\t|0.133|0.102|0.483|0.003|0.289|0.006|0.985|0.482|0.647|0.034|0.626|0.063|\n",
    "| max_depth = 5\t|0.152|0.104|0.484|0.006|0.476|0.011|0.985|0.482|0.647|0.037|0.612|0.069|\n",
    "| max_depth = 6\t|0.170|0.104|0.485|0.011|0.500|0.021|0.980|0.483|0.647|0.042|0.613|0.078|\n",
    "| max_depth = 7\t|0.186|0.106|0.485|0.015|0.460|0.029|0.971|0.483|0.645|0.056|0.611|0.100|\n",
    "| <b>max_depth = 8\t</b>|<b>0.203</b>|<b>0.106</b>|<b>0.486</b>|<b>0.014</b>|<b>0.444</b>|<b>0.027</b>|<b>0.969</b>|<b>0.484</b>|<b>0.645</b>|<b>0.066</b>|<b>0.614</b>|<b>0.116</b>|\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Wie bei der linearen Regression weisen die Ränder <i>Gut</i> und <i>Schlecht</i> sehr geringe Precision Werte auf. Dagegen konnte dieser bei der Kategorie <i>Durchschnitt</i> ein sehr gutes Ergebnis mit 0.969 erzielen.\n",
    "<br>\n",
    "<br>\n",
    "<b>LogisticRegression </b>\n",
    "<br>\n",
    "\n",
    "| Hyperparameter | R²TrainScore | R²TestScore | Accuracy| Schlecht Precision | Schlecht Recall | Schlecht F1 | Durchschnitt Precision | Durchschnitt Recall | Durchschnitt F1 | Gut Precision | Gut Recall | Gut F1 |\n",
    "| :---:| ---| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "|solver = 'liblinear', multi_class= 'ovr'| 0.999|0.514|0.514|0.231|0.485|0.312|0.754|0.511|0.609|0.356|0.55|0.432|\n",
    "|<b>solver = 'saga', multi_class= 'ovr'</b>|<b>1.0</b>|<b>0.202</b>|<b>0.525</b>|<b>0.166</b>|<b>0.528</b>|<b>0.252</b>|<b>0.863</b>|<b>0.511</b>|<b>0.642</b>|<b>0.25</b>|<b>0.642</b>|<b>0.359</b>|\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Das LogisticRegression Verfahren hat bei der Hyperparameter- Einstellung <i>solver = 'saga', multi_class= 'ovr'</i> genau dasselbe Ergebnis erzielt wie die lineare Regression. Die Einstellung <i>multi_class= 'ovr'</i> ist für binäre Daten geeignet.\n",
    "<br>\n",
    "<br>\n",
    "Im Vergleich zu den R²TrainScores aus Absatz [2.9 Fehlende Rotten Tomato Bewertungen mit Regression bestimmen](#2.9RegressionTomato) sind die Scores der hier aufgeführten Verfahren sehr gering. Der R²TrainScore ist wiederum bei LogisticRegression und Linear Regression jeweils 1. Dieses Phänomen konnten wir uns jedoch nicht richtig erklären. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Das Testverfahren ist in der Datai source.py als Funktion multivarianter_Regressions_Test einsehbar. In diesem Notebook kann der Test mit der Anweisung: \n",
    "<br><br>\n",
    "<font color=\"green\">from</font> source <font color=\"green\">import</font> multivarianter_Regressions_Test<br>\n",
    "result = multivarianter_Regressions_Test(df,genreDF_ohe, directorsDF_ohe, writersDF_ohe,actorsDF_ohe , productionDF_ohe, ratingQuantile)\n",
    "<br><br>\n",
    "in einer Code Zelle aufgerufen werden. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Ergebnis <a name=\"4.6result\"></a>\n",
    "Grundlegend konnte uns leider kein Verfahren überzeugen. BernoulliNB und die Regressionsvarianten LogisticRegression sowie lineare Regression haben zwar die besten Ergebnisse erzeilt, aber mit einer Accuracy um die 50%, würden wir die Modelle nicht in produktive Systeme einbinden. Das Diagramm \"Ratio Anzahl Dimensionen / Datensatzgröße\" aus Absatz [4.4 Reduktion der Dimensionen](#4.4dimensionReduction) zeigt, wie schlecht das Verhältnis der Anzahl an  Datensätzen zu der Anzahl an Dimensionen ist. Bei einem erneuten Versuch, die Beliebtheit zukünftiger Filme anhand der Autoren, Schauspieler, Regisseuren und Produktions-Firmen zu ermitteln, müssten viel mehr Datensätze genutzt werden, sodass das Verhältnis zu den Dimensionen schrumpft. \n",
    "<br>\n",
    "<br>\n",
    "Dennoch haben wir unseren \"Beliebheitsermittler\" mit Hilfe der BernoulliNB Klassifikation, als kleine Applikation für den Abschluss unserer Arbeit umgesetzt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Funktioniert mit BokehJS Version 1.2.0 unter Port: 8888\n",
    "from source import beliebtheitsermittler, createModels\n",
    "createModels(df, df_merged,ratingQuantile)\n",
    "beliebtheitsermittler(df,actorList, productionList , directorList, writersList, genreList,df_merged, ratingQuantile )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
